{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ï†ú4 Í≥†ÏßÄ : Ïã†Í≤ΩÎßù ÎßåÎì§Í∏∞ \n",
    "## STEP 51 : MNIST ÌïôÏäµ\n",
    "\n",
    "<p align='center'>\n",
    "  <img src='../assets/Í∑∏Î¶º 51-1.png' align='center' width='50%'>\n",
    "</p>\n",
    "\n",
    "Ïù¥Ï†ÑÏóê Íµ¨ÌòÑÌïú `Dataset` ÏóêÏÑú ÎØ∏ÎãàÎ∞∞Ïπò Îã®ÏúÑÎ°ú Îç∞Ïù¥ÌÑ∞Î•º Í∫ºÎÇ¥Îäî `DataLoader`Ïùò Í¥ÄÍ≥ÑÎäî ÏúÑÏùò Í∑∏Î¶ºÍ≥º Í∞ôÎã§.\n",
    "Ïù¥Î≤à Îã®Í≥ÑÏóêÏÑúÎäî ÏúÑÏùò Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï°∞Î•º ÌôúÏö©ÌïòÏó¨ ÏÉàÎ°úÏö¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÌïôÏäµÌï¥Î≥∏Îã§.  \n",
    "Ïö∞ÏÑ†  MNIST Îç∞Ïù¥ÌÑ∞ÏÖãÏù¥ Î¨¥ÏóáÏù∏ÏßÄ Î∂ÄÌÑ∞ Í∞ÑÎûµÌïòÍ≤å ÏÇ¥Ìé¥Î≥¥Ïûê.\n",
    "\n",
    "### 51.1 MNIST Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "\n",
    "`dezero/dataset.py` Ïóê MNIST ÌÅ¥ÎûòÏä§Î•º Ïù¥Ïö©Ìï¥ÏÑú Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú ÏÇ¥Ìé¥Î≥¥Ïûê. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "<class 'numpy.ndarray'> (1, 28, 28)\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dezero\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train=True,transform=None)\n",
    "test_set = dezero.datasets.MNIST(train=False,transform=None)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "\n",
    "x,t = train_set[0]\n",
    "print(type(x),x.shape)\n",
    "print(t)\n",
    "\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ ÏòàÏãú \n",
    "plt.imshow(x.reshape(28,28),cmap=\"gray\")\n",
    "plt.title(f\"label:{t}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ìï¥Îãπ Ïù¥ÎØ∏ÏßÄÎ•º Ïã†Í≤ΩÎßùÏóê ÎÑ£Í∏∞ Ï†Ñ ÏûÖÎ†•Îç∞Ïù¥ÌÑ∞Î•º  Îã§Ïùå ÏÑ∏ Í∞ÄÏßÄÎ•º Ï†ÑÏ≤òÎ¶¨ÌïúÎã§.\n",
    "\n",
    "1. (1,28,28) ÌòïÏÉÅ ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞Î•º `flatten`ÌïòÏó¨ **(784,)** ÌòïÏÉÅÏúºÎ°ú Î≥ÄÌôò\n",
    "2. Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖÏùÑ **np.float32 Î°ú Î≥ÄÌôò**ÌïúÎã§.\n",
    "3. `x /= 255.0` Î•º ÌÜµÌï¥ **0.0 ~ 1.0** ÏÇ¨Ïù¥Í∞Ä ÎêòÎèÑÎ°ù ÌïúÎã§.\n",
    "\n",
    "<span style='background-color : #ffdce0'>üí°<b>Ìï¥Îãπ Ï†ÑÏ≤òÎ¶¨Îäî `MNIST` ÌÅ¥ÎûòÏä§Ïóê Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÎã§. </b></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 51.2 MNIST ÌïôÏäµÌïòÍ∏∞ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.93, acc 0.54\n",
      "test loss 1.56, acc 0.74\n",
      "epoch 2, loss 1.30, acc 0.77\n",
      "test loss 1.06, acc 0.81\n",
      "epoch 3, loss 0.93, acc 0.82\n",
      "test loss 0.80, acc 0.84\n",
      "epoch 4, loss 0.75, acc 0.84\n",
      "test loss 0.66, acc 0.86\n",
      "epoch 5, loss 0.64, acc 0.85\n",
      "test loss 0.58, acc 0.86\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dezero\n",
    "from dezero import optimizers,DataLoader\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "\n",
    "\n",
    "log_interval = 1 # 20 epoch ÎßàÎã§ logging\n",
    "\n",
    "# ÌïòÏù¥Ìçº ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "######################################\n",
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "hidden_size = 1000\n",
    "######################################\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ ÏùΩÍ∏∞ / Î™®Îç∏, ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÉùÏÑ±\n",
    "######################################\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "test_set = dezero.datasets.MNIST(train=False)\n",
    "train_loader = DataLoader(train_set,batch_size)\n",
    "test_loader = DataLoader(test_set,batch_size,shuffle=False) # ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Îäî ÌèâÍ∞ÄÏö©Ïù¥ÎØÄÎ°ú shuffle=False\n",
    "######################################\n",
    "\n",
    "\n",
    "model = MLP((hidden_size, 10))\n",
    "optimizer = optimizers.SGD().setup(model)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss,sum_acc = 0,0\n",
    "\n",
    "    for x,t in train_loader : # ÎØ∏ÎãàÎ∞∞Ïπò \n",
    "        # Í∏∞Ïö∏Í∏∞ ÏÇ∞Ï∂ú / Îß§Í∞úÎ≥ÄÏàò Í∞±Ïã†\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        acc = F.accuracy(y,t) # Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "        sum_acc +=float(acc.data) * len(t) \n",
    "\n",
    "    # ÏóêÌè≠ÎßàÎã§ ÌïôÏäµ Í≤ΩÍ≥º Ï∂úÎ†•\n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "    if epoch % log_interval == 0:\n",
    "        print('epoch %d, loss %.2f, acc %.2f' % (epoch + 1, avg_loss,avg_acc))\n",
    "        \n",
    "    sum_loss, sum_acc = 0,0\n",
    "    with dezero.no_grad():\n",
    "        for x,t in test_loader:\n",
    "            # Í∏∞Ïö∏Í∏∞ ÏÇ∞Ï∂ú / Îß§Í∞úÎ≥ÄÏàò Í∞±Ïã†\n",
    "            y = model(x)\n",
    "            loss = F.softmax_cross_entropy(y, t)\n",
    "            acc = F.accuracy(y,t) # Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
    "\n",
    "            sum_loss += float(loss.data) * len(t)\n",
    "            sum_acc +=float(acc.data) * len(t) \n",
    "            \n",
    "    avg_loss = sum_loss / len(test_set)\n",
    "    avg_acc = sum_acc / len(test_set)\n",
    "    if epoch % log_interval == 0:\n",
    "        print('test loss %.2f, acc %.2f' % (avg_loss,avg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 51.3 Î™®Îç∏ Í∞úÏÑ†ÌïòÍ∏∞ \n",
    "\n",
    "Î∞©Í∏à ÌïôÏäµÌïú Î™®Îç∏ `MLP`Ïùò ÌôúÏÑ±Ìôî Ìï®ÏàòÎäî **sigmoid** Ìï®ÏàòÏòÄÎã§. Í∑∏Îü∞Îç∞ ÏµúÍ∑ºÏóêÎäî **ReLU(Rectified Linear Unit)** ÎùºÎäî Ìï®ÏàòÍ∞Ä Îçî ÏûêÏ£º ÏÇ¨Ïö©ÎêòÎäîÎç∞, Ìï¥Îãπ Ìï®ÏàòÎäî Îã§Ïùå ÌäπÏßïÏùÑ Í∞ÄÏßÑÎã§.\n",
    "$$\n",
    "f(x) = \\begin{cases}\n",
    "x, & \\text{if } x > 0 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- ÏûÖÎ†•Ïù¥ 0Î≥¥Îã§ ÌÅ¨Î©¥ Í∑∏ÎåÄÎ°ú Ï∂úÎ†•\n",
    "- ÏûÖÎ†•Ïù¥ 0 Ïù¥ÌïòÎ©¥ 0ÏùÑ Ï∂úÎ†•\n",
    "\n",
    "<span style='background-color : #ffdce0'>üí°<b>Ï¶â, ReLUÎäî Ïã†Ìò∏Î•º `ÌÜµÍ≥º` ÎòêÎäî `Î¥âÏáÑ` ÌïúÎã§.</b></span>\n",
    "\n",
    "Í∑∏ÎûòÏÑú Ìï¥Îãπ Ìï®ÏàòÎ•º Íµ¨ÌòÑÌï¥Î≥¥Ïûê.\n",
    "\n",
    "```python\n",
    "class ReLU(Function):\n",
    "    def forward(self, x):\n",
    "        y = np.maximum(x, 0.0) # 1. x ÏôÄ 0.0 Ï§ë ÌÅ∞ Í∞íÏùÑ Î∞òÌôò.\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        mask = x.data > 0 # 2. 0 Î≥¥Îã§ ÌÅ∞ Í∞íÏùÄ Í∑∏ÎåÄÎ°ú Í∏∞Ïö∏Í∏∞Î•º ÌùòÎ†§Î≥¥ÎÇ¥Ï£ºÍ≥†, Ïù¥ÌïòÎ©¥ Í∏∞Ïö∏Í∏∞Î•º 0ÏúºÎ°ú ÏÑ§Ï†ïÌïòÎäî mask\n",
    "        gx = gy * mask # 3. Í∏∞Ïö∏Í∏∞ Í≥±\n",
    "        return gx\n",
    "\n",
    "def relu(x):\n",
    "    return ReLU()(x)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.23, acc 0.93\n",
      "test loss 0.11, acc 0.97\n",
      "epoch 2, loss 0.09, acc 0.97\n",
      "test loss 0.08, acc 0.98\n",
      "epoch 3, loss 0.05, acc 0.98\n",
      "test loss 0.07, acc 0.98\n",
      "epoch 4, loss 0.04, acc 0.99\n",
      "test loss 0.07, acc 0.98\n",
      "epoch 5, loss 0.03, acc 0.99\n",
      "test loss 0.06, acc 0.98\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import dezero\n",
    "from dezero import optimizers,DataLoader\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "\n",
    "\n",
    "log_interval = 1 # 20 epoch ÎßàÎã§ logging\n",
    "\n",
    "# ÌïòÏù¥Ìçº ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "hidden_size = 1000\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ ÏùΩÍ∏∞ / Î™®Îç∏, ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÉùÏÑ±\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "test_set = dezero.datasets.MNIST(train=False)\n",
    "train_loader = DataLoader(train_set,batch_size)\n",
    "test_loader = DataLoader(test_set,batch_size,shuffle=False) # ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Îäî ÌèâÍ∞ÄÏö©Ïù¥ÎØÄÎ°ú shuffle=False\n",
    "\n",
    "######################################\n",
    "# activation, optimizer  Î≥ÄÍ≤Ω\n",
    "model = MLP((hidden_size, 10),activation=F.relu)\n",
    "optimizer = optimizers.Adam().setup(model)\n",
    "######################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss,sum_acc = 0,0\n",
    "\n",
    "    for x,t in train_loader : # ÎØ∏ÎãàÎ∞∞Ïπò \n",
    "        # Í∏∞Ïö∏Í∏∞ ÏÇ∞Ï∂ú / Îß§Í∞úÎ≥ÄÏàò Í∞±Ïã†\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        acc = F.accuracy(y,t) # Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "        sum_acc +=float(acc.data) * len(t) \n",
    "\n",
    "    # ÏóêÌè≠ÎßàÎã§ ÌïôÏäµ Í≤ΩÍ≥º Ï∂úÎ†•\n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "    if epoch % log_interval == 0:\n",
    "        print('epoch %d, loss %.2f, acc %.2f' % (epoch + 1, avg_loss,avg_acc))\n",
    "        \n",
    "    sum_loss, sum_acc = 0,0\n",
    "    with dezero.no_grad():\n",
    "        for x,t in test_loader:\n",
    "            # Í∏∞Ïö∏Í∏∞ ÏÇ∞Ï∂ú / Îß§Í∞úÎ≥ÄÏàò Í∞±Ïã†\n",
    "            y = model(x)\n",
    "            loss = F.softmax_cross_entropy(y, t)\n",
    "            acc = F.accuracy(y,t) # Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
    "\n",
    "            sum_loss += float(loss.data) * len(t)\n",
    "            sum_acc +=float(acc.data) * len(t) \n",
    "            \n",
    "    avg_loss = sum_loss / len(test_set)\n",
    "    avg_acc = sum_acc / len(test_set)\n",
    "    if epoch % log_interval == 0:\n",
    "        print('test loss %.2f, acc %.2f' % (avg_loss,avg_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3584091cda227b8e59fda59e5fdf3aec4997f3a2464c55243d7618073e2ad776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
