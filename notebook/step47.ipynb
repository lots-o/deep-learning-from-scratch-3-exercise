{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì œ4 ê³ ì§€ : ì‹ ê²½ë§ ë§Œë“¤ê¸° \n",
    "## STEP 47 : ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ì™€ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨\n",
    "\n",
    "ì´ì „ ë‹¨ê³„ì—ì„œëŠ” íšŒê·€ë¬¸ì œë¥¼ í’€ì–´ë´¤ëŠ”ë°, ì•ìœ¼ë¡œëŠ” `multi-class classification` ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.\n",
    "\n",
    "\n",
    "### 47.1 ìŠ¬ë¼ì´ìŠ¤ ì¡°ì‘ í•¨ìˆ˜\n",
    "\n",
    "êµ¬ì²´ì ì¸ êµ¬í˜„ì€ ì¶”í›„ ë¶€ë¡.Bë¥¼ ì°¸ê³ í•˜ë„ë¡ í•˜ê³ , ì‚¬ìš©ë²•ì— ëŒ€í•´ì„œë§Œ ìš°ì„  ì‚´í´ë³¸ë‹¤.\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='../assets/ê·¸ë¦¼ 47-1.png' align='center' width='50%'>\n",
    "</p>\n",
    "\n",
    "`get_item()` ì€ `Variable` ì˜ ë‹¤ì°¨ì› ë°°ì—´ ì¤‘ì—ì„œ ì¼ë¶€ë¥¼ ìŠ¬ë¼ì´ìŠ¤ í•˜ì—¬ ë½‘ì•„ì¤€ë‹¤. ì¦‰ **ìŠ¬ë¼ì´ìŠ¤ëŠ” ë°ì´í„°ì˜ ì¼ë¶€ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ì—­í• **ì´ë¯€ë¡œ, **ë°ì´í„°ê°€ ì¶”ì¶œëœ ìœ„ì¹˜ì—ë§Œ ê¸°ìš¸ê¸°ë¥¼ 1ë¡œ ì„¤ì •í•˜ê³  ì´ì™¸ì—ëŠ” 0ìœ¼ë¡œ ì„¤ì •**í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ¬ë¼ì´ìŠ¤ :  variable([4 5 6])\n",
      "==========\n",
      "ê¸°ìš¸ê¸° :  variable([[0 0 0]\n",
      "          [1 1 1]])\n",
      "==========\n",
      "variable([[1 2 3]\n",
      "          [1 2 3]\n",
      "          [4 5 6]])\n",
      "==========\n",
      "variable([4 5 6])\n",
      "variable([3 6])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np \n",
    "from dezero import Variable\n",
    "import dezero.functions as F \n",
    "\n",
    "x = Variable(np.array([[1,2,3],[4,5,6]]))\n",
    "y = F.get_item(x,1)\n",
    "print(\"ìŠ¬ë¼ì´ìŠ¤ : \", y)\n",
    "print(\"=\"*10)\n",
    "y.backward()\n",
    "print(\"ê¸°ìš¸ê¸° : \",x.grad)\n",
    "print(\"=\"*10)\n",
    "\n",
    "# ë˜í•œ ê°™ì€ ì¸ë±ìŠ¤ë¥¼ ë°˜ë³µ ì§€ì •í•˜ì—¬ ë™ì¼í•œ ì›ì†Œë¥¼ ì—¬ëŸ¬ ë²ˆ ë¹¼ë‚¼ ìˆ˜ ìˆë‹¤.\n",
    "indices = np.array([0,0,1])\n",
    "y = F.get_item(x,indices)\n",
    "print(y)\n",
    "\n",
    "print(\"=\"*10)\n",
    "# ë˜í•œ dezero/core.py ì—ì„œ Variable.__getitem__ = dezero.functions.get_item ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ìŠ¬ë¼ì´ìŠ¤ ì—°ì‚°ì´ ê°€ëŠ¥í•˜ë©° ì—­ì „íŒŒ ì—­ì‹œ ì˜ ì‘ë™í•œë‹¤.\n",
    "y = x[1]\n",
    "print(y)\n",
    "\n",
    "y = x[:,2]\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 47.2 ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜\n",
    "ì‹ ê²½ë§ì˜ ì¶œë ¥ì€ ë‹¨ìˆœí•œ ìˆ˜ì¹˜ì¸ë°, ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•´ ì´ ìˆ˜ì¹˜ë¥¼ 'í™•ë¥ 'ë¡œ ë³€í™˜í•  í•„ìš”ê°€ ìˆë‹¤.  \n",
    "ë‹¤ìŒ softmax functionì„ ì´ìš©í•˜ë©´ í™•ë¥ ë¡œ ë³€í™˜ ê°€ëŠ¥í•˜ë‹¤. \n",
    "\n",
    "$$\n",
    "p_k = \\frac{e^{y_k}}{\\sum_{i=1}^n e^{y_i}}\n",
    "$$\n",
    "\n",
    "êµ¬ì²´ì ìœ¼ë¡œ ì‚´í´ë³´ë©´, í•©ìˆ˜ì˜ ì…ë ¥ $y_k$  ì´ $n$ ê°œ (í´ë˜ìŠ¤ ìˆ˜) ë¼ê³  ê°€ì •í•˜ë©´ $p_1+p_2+\\cdots+p_n = 1 $ ì´ ì„±ë¦½í•˜ì—¬ $(p_1,p_2,\\cdots,p_n)$ì˜ ì›ì†Œ ê°ê°ì„ í™•ë¥ ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='../assets/ê·¸ë¦¼ 47-2.png' align='center' width='70%'>\n",
    "</p>\n",
    "\n",
    "ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ ìœ„ì˜ ê·¸ë¦¼ì„ ë³´ë©´ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ê³ ë‚˜ë©´ í™•ë¥  $p_1,p_2,p_3$ë¡œ í‘œí˜„ë˜ê³  í•©ì´ 1 ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "<span style='background-color : #ffdce0'>ğŸ’¡<b>ì£¼ì˜í•´ì•¼í•  ê²ƒì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ëŠ” ì§€ìˆ˜í•¨ìˆ˜ë¡œ ì´ë£¨ì–´ì ¸ ìˆê¸° ë•Œë¬¸ì— ë„ˆë¬´ ì»¤ì§€ê±°ë‚˜ ì‘ì•„ì§ˆ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì˜¤ë²„í”Œë¡œìš° ë¬¸ì œë¥¼ ì˜ ë‹¤ë¤„ì¤˜ì•¼ í•˜ëŠ”ë° ì‹¤ì œ êµ¬í˜„ì‹œì—ëŠ” $p_k = \\frac{Ce^{y_k}}{C\\sum_{i=1}^n e^{y_i}}=\\frac{e^{y_k}+\\log C}{\\sum_{i=1}^n e^{y_i}+\\log C}=\\frac{e^{y_k}+C'}{\\sum_{i=1}^n e^{y_i}+C'}$ì™€ ê°™ì´   ì§€ìˆ˜í•¨ìˆ˜ê³„ì‚°ì‹œì—ëŠ” ì–´ë–¤ ì •ìˆ˜ë¥¼ ë”í•˜ê±°ë‚˜ ë¹¼ë”ë¼ë„ ê²°ê³¼ëŠ” ë°”ë€Œì§€ ì•ŠëŠ” ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì´ìš©í•´ ìµœëŒ€ê°’ì„ ë¹¼ì„œ ì˜¤ë²„í”Œë¡œìš°ë¥¼ ë§‰ì•„ì¤€ë‹¤.</b></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹ ê²½ë§ ì¶œë ¥ :  variable([[ 0.12806286 -0.08324128  0.3620511 ]])\n",
      "ì†Œí”„íŠ¸ ë§¥ìŠ¤ ì ìš© í›„ :  variable([[0.32539823 0.26341892 0.41118285]])\n"
     ]
    }
   ],
   "source": [
    "from dezero import Variable, as_variable\n",
    "from dezero.models import MLP\n",
    "import dezero.functions as F \n",
    "\n",
    "def softmax1d(x):\n",
    "    x = as_variable(x)\n",
    "    y = F.exp(x)\n",
    "    sum_y = F.sum(y)\n",
    "    return y / sum_y\n",
    "\n",
    "x = Variable(np.array([[0.2,-0.4]]))\n",
    "model = MLP((10,3))\n",
    "y = model(x)\n",
    "p = softmax1d(y)\n",
    "print(\"ì‹ ê²½ë§ ì¶œë ¥ : \",y)\n",
    "print(\"ì†Œí”„íŠ¸ ë§¥ìŠ¤ ì ìš© í›„ : \",p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì–´ì„œ **ë°°ì¹˜ ë°ì´í„°ì—ì„œë„ ì ìš© ê°€ëŠ¥**í•˜ê²Œ í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•œë‹¤.\n",
    "```python\n",
    "def softmax_simple(x,axis=1):\n",
    "    x = as_variable(x)\n",
    "    y = exp(x) # DeZero exp í•¨ìˆ˜\n",
    "    sum_y = sum(y,axis=axis,keepdims=True)\n",
    "    return y / sum_y \n",
    "```\n",
    "\n",
    "ì¶”ê°€ì ìœ¼ë¡œ, ë” ë‚˜ì€ êµ¬í˜„ ë°©ì‹ì„ ìœ„í•´ `Function`ì„ ìƒì†í•˜ì—¬ `Softmax` í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•´ë³´ì.\n",
    "```python\n",
    "class Softmax(Function):\n",
    "    def __init__(self, axis=1):\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x - x.max(axis=self.axis, keepdims=True) # ì˜¤ë²„í”Œë¡œìš° ë°©ì§€ë¥¼ ìœ„í•´ ìµœëŒ€ê°’ì„ ë¹¼ì¤€ë‹¤.\n",
    "        y = np.exp(y)\n",
    "        y /= y.sum(axis=self.axis, keepdims=True)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        y = self.outputs[0]()\n",
    "        gx = y * gy\n",
    "        sumdx = gx.sum(axis=self.axis, keepdims=True)\n",
    "        gx -= y * sumdx\n",
    "        return gx\n",
    "\n",
    "def softmax(x, axis=1):\n",
    "    return Softmax(axis)(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 47.3 êµì°¨ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨ \n",
    "ì„ í˜•íšŒê·€ì—ì„œëŠ” `MSE` ë¥¼ ì†ì‹¤í•¨ìˆ˜ë¡œ ì‚¬ìš©í–ˆë‹¤ë©´, multi-class classification  ì—ì„œëŠ” `êµì°¨ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨ (cross entropy error)` ë¥¼ ì†ì‹¤í•¨ìˆ˜ë¡œ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. \n",
    "\n",
    "$$\n",
    "L = - \\sum_k t_k\\log p_k\n",
    "$$\n",
    "\n",
    "ì—¬ê¸°ì„œ $t_k$ ëŠ” ì •ë‹µ ë°ì´í„°ì˜ $k$ì°¨ì›ì˜ ê°’ìœ¼ë¡œ ì •ë‹µì´ë©´ 1, ì•„ë‹ˆë©´ 0ìœ¼ë¡œ í‘œí˜„ë˜ëŠ” ì›í•« ë²¡í„°ë¡œ ì‹¤ì œë¶„í¬ì´ê³ ,  $p_k$ ëŠ” ì‹ ê²½ë§ì—ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ì ìš©í•œ í•¨ìˆ˜ ê°’ìœ¼ë¡œ ì˜ˆì¸¡ ë¶„í¬ì´ë‹¤.\n",
    " \n",
    "\n",
    "ì´ë¥¼ ì¡°ê¸ˆë” ê°„ë‹¨í•˜ê²Œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. \n",
    "$$\n",
    "L= -\\log\\mathbf{p}[t]\n",
    "$$\n",
    "\n",
    "êµ¬ì²´ì ìœ¼ë¡œ ì‚´í´ë³´ë©´, ë§Œì•½ $\\mathbf{t}=(0,0,1),\\mathbf{p}=(p_0,p_1,p_2)$ë¼ê³  í•˜ë©´ $L=-\\log p_2$ì´ë¯€ë¡œ ì •ë‹µí´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ë²ˆí˜¸ì˜ í™•ë¥  $\\mathbf{p}$ë¥¼ ì¶”ì¶œí•˜ëŠ”ê²ƒê³¼ ê°™ìœ¼ë¯€ë¡œ, ìœ„ì™€ ê°™ì´ í‘œí˜„ì´ ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "<span style='background-color : #ffdce0'>ğŸ’¡<b>ì´ë²ˆ ì„¤ëª…ì€ ë°ì´í„°ê°€ í•˜ë‚˜ì¸ ê²½ìš°ì— í•´ë‹¹í•˜ê³  ë§Œì•½ ë°ì´í„°ê°€ $N$ê°œë¼ë©´ í‰ê·  êµì°¨ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨ë¥¼ êµ¬í•´ì•¼ í•œë‹¤.</b></span>\n",
    "\n",
    "ì´ì œ `ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜` ì™€ `êµì°¨ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨` ë¥¼ í•œêº¼ë²ˆì— ìˆ˜í–‰í•˜ëŠ” `softmax_cross_entropy_simple(x,t)` í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ë³´ì.\n",
    "\n",
    "\n",
    "```python\n",
    "def softmax_cross_entropy_simple(x, t):\n",
    "    '''\n",
    "    x : ì‹ ê²½ë§ì—ì„œ ì†Œí”„íŠ¸ë§¥ìˆ˜ ì ìš©ì „ì˜ ì¶œë ¥ê°’\n",
    "    t : ì •ë‹µ ë°ì´í„°ë¡œ ì •ë‹µ í´ë˜ìŠ¤ì˜ ë²ˆí˜¸ (ì›í•« ë²¡í„°ê°€ ì•„ë‹ˆë‹¤)\n",
    "    '''\n",
    "    x, t = as_variable(x), as_variable(t)\n",
    "    N = x.shape[0]\n",
    "    p = softmax(x)\n",
    "    p = clip(p, 1e-15, 1.0)  # To avoid log(0), ë§Œì•½ pê°€ 0ì´ë©´ 1e-15ë¡œ ëŒ€ì²´, 1.0ì„ ë„˜ìœ¼ë©´ 1.0\n",
    "    log_p = log(p)\n",
    "    tlog_p = log_p[np.arange(N), t.data]\n",
    "    y = -1 * sum(tlog_p) / N\n",
    "    return y\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.9820149162942775)\n"
     ]
    }
   ],
   "source": [
    "from dezero import Variable, as_variable\n",
    "from dezero.models import MLP\n",
    "import dezero.functions as F \n",
    "\n",
    "\n",
    "x = np.array([[0.2,-0.4],[0.3,0.5],[1.3,-3.2],[2.1,0.3]])\n",
    "t = np.array([2,0,1,0])\n",
    "model = MLP((10,3))\n",
    "y = model(x)\n",
    "loss = F.softmax_cross_entropy(y,t)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3584091cda227b8e59fda59e5fdf3aec4997f3a2464c55243d7618073e2ad776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
