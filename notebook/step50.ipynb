{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제4 고지 : 신경망 만들기 \n",
    "## STEP 50 : 미니배치를 뽑아주는 DataLoader\n",
    "\n",
    "이전 단계에서는 `Dataset` 클래스를 만들어 통일된 인터페이스로 데이터셋을 다루게 했다면, 이제는 미니배치를 뽑아주는 `DataLoader` 클래스를 구현한다. 이를 위해 우선 `Iterator` 가 무엇인지 알아보도록 한다.\n",
    "\n",
    "### 50.1 반복자(Iterator)란?\n",
    "\n",
    "이름에서 알 수 있듯이 원소를 반복하여 꺼내준다.\n",
    "\n",
    "```python\n",
    ">>> t= [1,2,3]\n",
    ">>> x= iter(t)\n",
    ">>> next(x)\n",
    "1\n",
    ">>> next(x)\n",
    "2\n",
    ">>> next(x)\n",
    "3\n",
    ">>> next(x)\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "StopIteration\n",
    "```\n",
    "\n",
    "구체적으로 살펴보면 다음과 같다.\n",
    "\n",
    "- 리스트를 반복자로 변환하기 위해 `iter()` 를 사용 \n",
    "- `next()` 를 이용해 원소를 차례대로 호출 \n",
    "\n",
    "<span style='background-color : #ffdce0'>💡<b> `for` 문에서 리스트의 원소를 꺼낼때 내부적으로 반복자로 변환된다.</b></span>\n",
    "\n",
    "파이썬에서는 다음과 같이 \n",
    "\n",
    "1. `__iter__()` 구현하고 자기 자신(`self`) 를 반환한다.\n",
    "2. `__next__()` 에서 다음 원소를 반환하도록 구현한다. 이때 반환할 원소가 없다면 `StopIteration` 을 발생시킨다. \n",
    "\n",
    "반복자를 직접 정의할 수 있다.\n",
    "\n",
    "```python\n",
    "class MyIterator:\n",
    "  def __init__(self,max_cnt):\n",
    "    self.max_cnt = max_cnt \n",
    "    self.cnt = 0\n",
    "  \n",
    "  def __iter__(self):\n",
    "    return(self)\n",
    "  \n",
    "  def __next__(self):\n",
    "    if self.cnt == self.max_cnt :\n",
    "      raise StopIteration()\n",
    "    \n",
    "    self.cnt += 1 \n",
    "    return self.cnt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "class MyIterator:\n",
    "  def __init__(self,max_cnt):\n",
    "    self.max_cnt = max_cnt \n",
    "    self.cnt = 0\n",
    "  \n",
    "  def __iter__(self):\n",
    "    return(self)\n",
    "  \n",
    "  def __next__(self):\n",
    "    if self.cnt == self.max_cnt :\n",
    "      raise StopIteration()\n",
    "    \n",
    "    self.cnt += 1 \n",
    "    return self.cnt\n",
    "\n",
    "obj = MyIterator(5)\n",
    "for x in obj:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 반복자에 대해 이해했으니, `DataLoader`를 구현해본다.\n",
    "\n",
    "\n",
    "```python\n",
    "import math \n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        self.dataset = dataset # Dataset\n",
    "        self.batch_size = batch_size \n",
    "        self.shuffle = shuffle # 훈련용 데이터셋을 위해 기본적으로 shuffle = True\n",
    "        self.data_size = len(dataset)\n",
    "        self.max_iter = math.ceil(self.data_size / batch_size)\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.iteration = 0\n",
    "        if self.shuffle:\n",
    "            self.index = np.random.permutation(len(self.dataset))\n",
    "        else:\n",
    "            self.index = np.arange(len(self.dataset))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.iteration >= self.max_iter:\n",
    "            self.reset()\n",
    "            raise StopIteration\n",
    "\n",
    "        i, batch_size = self.iteration, self.batch_size\n",
    "        batch_index = self.index[i * batch_size:(i + 1) * batch_size]\n",
    "        batch = [self.dataset[i] for i in batch_index]\n",
    "\n",
    "        x = np.array([example[0] for example in batch])\n",
    "        t = np.array([example[1] for example in batch])\n",
    "\n",
    "        self.iteration += 1\n",
    "        return x, t\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "\n",
    "```\n",
    "\n",
    "### 50.2 DataLoader 사용하기\n",
    "\n",
    "이제 `DataLoader` 를 사용하면 미니배치를 꺼내오는 일이 간단해진다. 시험삼아 학습을 가정하고 사용해보도록 하자.\n",
    "\n",
    "```python\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2) (10,)\n",
      "(10, 2) (10,)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from dezero.datasets import Spiral\n",
    "from dezero import DataLoader\n",
    "\n",
    "\n",
    "batch_size = 10 \n",
    "max_epoch = 1 \n",
    "\n",
    "train_set = Spiral(train=True)\n",
    "test_set = Spiral(train=False)\n",
    "train_loader = DataLoader(train_set,batch_size)\n",
    "test_loader = DataLoader(test_set,batch_size,shuffle=False) # 테스트 데이터는 평가용이므로 shuffle=False\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for x,t in train_loader:\n",
    "        print(x.shape,t.shape)\n",
    "        break\n",
    "    \n",
    "    for x,t in test_loader:\n",
    "        print(x.shape,t.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50.3 accuracy 함수 구현하기\n",
    "성능 평가를 위해  `accuracy` 함수를 추가한다.\n",
    "\n",
    "```python\n",
    "def accuracy(y, t):\n",
    "    y, t = as_variable(y), as_variable(t)\n",
    "\n",
    "    pred = y.data.argmax(axis=1).reshape(t.shape)\n",
    "    result = (pred == t.data)\n",
    "    acc = result.mean()\n",
    "    return Variable(as_array(acc))\n",
    "\n",
    "import numpy as np\n",
    "import dezero.functions as F \n",
    "\n",
    "y = np.array([[0.2,0.8,0],[0.1,0.9,0],[0.8,0.1,0.1]])\n",
    "t = np.array([1,2,0])\n",
    "acc = F.accuracy(y,t)\n",
    "print(acc)\n",
    "# variable(0.6666666666666666)\n",
    "```\n",
    "\n",
    "\n",
    "### 50.4 스파이럴 데이터셋 학습 코드\n",
    "\n",
    "이제 `DataLoader` 와 `accuracy` 를 활용해 spiral dataset 을 학습해본다.\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='../assets/그림 50-1.png' align='center' width='80%'>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.09, acc 0.40\n",
      "test loss 1.05, acc 0.33\n",
      "epoch 21, loss 0.75, acc 0.56\n",
      "test loss 0.76, acc 0.61\n",
      "epoch 41, loss 0.70, acc 0.58\n",
      "test loss 0.71, acc 0.61\n",
      "epoch 61, loss 0.60, acc 0.68\n",
      "test loss 0.62, acc 0.62\n",
      "epoch 81, loss 0.44, acc 0.80\n",
      "test loss 0.45, acc 0.79\n",
      "epoch 101, loss 0.31, acc 0.86\n",
      "test loss 0.33, acc 0.88\n",
      "epoch 121, loss 0.24, acc 0.93\n",
      "test loss 0.25, acc 0.91\n",
      "epoch 141, loss 0.19, acc 0.94\n",
      "test loss 0.22, acc 0.92\n",
      "epoch 161, loss 0.17, acc 0.95\n",
      "test loss 0.20, acc 0.93\n",
      "epoch 181, loss 0.16, acc 0.94\n",
      "test loss 0.20, acc 0.93\n",
      "epoch 201, loss 0.14, acc 0.95\n",
      "test loss 0.17, acc 0.94\n",
      "epoch 221, loss 0.14, acc 0.95\n",
      "test loss 0.16, acc 0.95\n",
      "epoch 241, loss 0.13, acc 0.95\n",
      "test loss 0.16, acc 0.95\n",
      "epoch 261, loss 0.12, acc 0.96\n",
      "test loss 0.15, acc 0.95\n",
      "epoch 281, loss 0.12, acc 0.97\n",
      "test loss 0.15, acc 0.96\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import dezero\n",
    "from dezero import optimizers,DataLoader\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "\n",
    "\n",
    "log_interval = 20 # 20 epoch 마다 logging\n",
    "\n",
    "# 하이퍼 파라미터 설정\n",
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "lr = 1.0\n",
    "\n",
    "\n",
    "# 데이터 읽기 / 모델, 옵티마이저 생성\n",
    "######################################\n",
    "train_set = dezero.datasets.Spiral(train=True)\n",
    "test_set = dezero.datasets.Spiral(train=False)\n",
    "train_loader = DataLoader(train_set,batch_size)\n",
    "test_loader = DataLoader(test_set,batch_size,shuffle=False) # 테스트 데이터는 평가용이므로 shuffle=False\n",
    "######################################\n",
    "\n",
    "\n",
    "model = MLP((hidden_size, 3))\n",
    "optimizer = optimizers.SGD(lr).setup(model)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss,sum_acc = 0,0\n",
    "\n",
    "    ######################################\n",
    "    for x,t in train_loader : # 미니배치 \n",
    "    ######################################\n",
    "        # 기울기 산출 / 매개변수 갱신\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        ######################################\n",
    "        acc = F.accuracy(y,t) # 정확도 계산\n",
    "        ######################################\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "        sum_acc +=float(acc.data) * len(t) \n",
    "\n",
    "    # 에폭마다 학습 경과 출력\n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "    if epoch % log_interval == 0:\n",
    "        print('epoch %d, loss %.2f, acc %.2f' % (epoch + 1, avg_loss,avg_acc))\n",
    "        \n",
    "    sum_loss, sum_acc = 0,0\n",
    "    with dezero.no_grad():\n",
    "        for x,t in test_loader:\n",
    "            # 기울기 산출 / 매개변수 갱신\n",
    "            y = model(x)\n",
    "            loss = F.softmax_cross_entropy(y, t)\n",
    "            ######################################\n",
    "            acc = F.accuracy(y,t) # 정확도 계산\n",
    "            ######################################\n",
    "\n",
    "            sum_loss += float(loss.data) * len(t)\n",
    "            sum_acc +=float(acc.data) * len(t) \n",
    "            \n",
    "    avg_loss = sum_loss / len(test_set)\n",
    "    avg_acc = sum_acc / len(test_set)\n",
    "    if epoch % log_interval == 0:\n",
    "        print('test loss %.2f, acc %.2f' % (avg_loss,avg_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3584091cda227b8e59fda59e5fdf3aec4997f3a2464c55243d7618073e2ad776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
